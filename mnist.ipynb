{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\123\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-7fc5e2d18cc1>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\123\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\123\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting f:/MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\123\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting f:/MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\123\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting f:/MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting f:/MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\123\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"f:/MNIST_data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Graph().as_default() as g:\n",
    "    # 输入、标记占位符\n",
    "    inputs = tf.placeholder(shape=[None, 784], dtype=tf.float32)\n",
    "    labels = tf.placeholder(shape=[None, 10], dtype=tf.float32)\n",
    "    \n",
    "    \n",
    "    # 创建128个隐藏层神经元参数\n",
    "    hid1_weight = tf.Variable(tf.random_normal([784, 64]), name='hidden_weight')\n",
    "    hid1_bias = tf.Variable(tf.zeros([64, ]), name='hidden_bias')\n",
    "    hid1_op = tf.nn.relu(tf.matmul(inputs, hid1_weight) + hid1_bias)\n",
    "    hid2_weight=tf.Variable(tf.random_normal([64,128]))\n",
    "    hid2_bias=tf.Variable(tf.zeros([128,]))\n",
    "    hidden_output=tf.matmul(hid1_op,hid2_weight)+hid2_bias\n",
    "    # 创建输出层10个神经元参数\n",
    "    output_weight = tf.Variable(tf.random_normal([128, 10], name='output_weight'))\n",
    "    output_bias = tf.Variable(tf.zeros([10, ]), name='output_bias')\n",
    "    # 输出层前向传播\n",
    "    logits = tf.matmul(hidden_output, output_weight) + output_bias\n",
    "    output = tf.nn.softmax(logits)\n",
    "    \n",
    "    \n",
    "    # 代价函数\n",
    "    loss = tf.reduce_mean(-1 * tf.reduce_sum(\n",
    "        labels * tf.log(output + 1e-7),\n",
    "        axis=1))\n",
    "    \n",
    "    \n",
    "    # 正确率\n",
    "    acc = tf.reduce_mean(\n",
    "        tf.cast(tf.equal(tf.argmax(labels, axis=1), tf.argmax(output, axis=1)),\n",
    "                tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step     0, loss 15.1107, acc 0.1274\n",
      "step  1000, loss 12.5923, acc 0.3026\n",
      "step  2000, loss 8.5627, acc 0.3666\n",
      "step  3000, loss 9.5701, acc 0.4111\n",
      "step  4000, loss 8.0590, acc 0.4583\n",
      "step  5000, loss 10.0738, acc 0.4609\n",
      "step  6000, loss 11.5849, acc 0.4669\n",
      "step  7000, loss 8.0590, acc 0.4615\n",
      "step  8000, loss 8.5627, acc 0.4777\n",
      "step  9000, loss 7.0517, acc 0.5509\n",
      "step 10000, loss 11.5849, acc 0.5559\n",
      "step 11000, loss 7.0517, acc 0.5607\n",
      "step 12000, loss 5.5580, acc 0.5639\n",
      "step 13000, loss 9.5701, acc 0.5685\n",
      "step 14000, loss 9.0664, acc 0.5614\n",
      "step 15000, loss 4.5332, acc 0.5758\n",
      "step 16000, loss 8.0590, acc 0.5750\n",
      "step 17000, loss 6.0443, acc 0.5730\n",
      "step 18000, loss 6.0415, acc 0.5662\n",
      "step 19000, loss 7.5554, acc 0.5699\n",
      "step 20000, loss 7.5554, acc 0.5832\n",
      "step 21000, loss 7.5554, acc 0.5868\n",
      "step 22000, loss 6.5480, acc 0.5623\n",
      "step 23000, loss 6.5480, acc 0.6121\n",
      "step 24000, loss 5.0369, acc 0.6205\n",
      "step 25000, loss 6.3611, acc 0.6337\n",
      "step 26000, loss 7.0517, acc 0.6332\n",
      "step 27000, loss 6.0443, acc 0.6228\n",
      "step 28000, loss 7.5554, acc 0.6423\n",
      "step 29000, loss 5.0369, acc 0.6394\n",
      "step 30000, loss 4.5332, acc 0.6320\n",
      "step 31000, loss 3.0221, acc 0.6467\n",
      "step 32000, loss 7.5554, acc 0.6341\n",
      "step 33000, loss 6.0443, acc 0.6437\n",
      "step 34000, loss 5.5406, acc 0.6509\n",
      "step 35000, loss 8.0590, acc 0.6519\n",
      "step 36000, loss 5.0369, acc 0.6533\n",
      "step 37000, loss 4.0295, acc 0.6482\n",
      "step 38000, loss 7.0517, acc 0.6489\n",
      "step 39000, loss 4.5332, acc 0.6536\n",
      "step 40000, loss 3.5258, acc 0.6423\n",
      "step 41000, loss 8.0590, acc 0.6504\n",
      "step 42000, loss 8.0590, acc 0.6548\n",
      "step 43000, loss 6.5480, acc 0.6502\n",
      "step 44000, loss 7.0517, acc 0.6526\n",
      "step 45000, loss 5.0369, acc 0.6558\n",
      "step 46000, loss 3.5258, acc 0.6576\n",
      "step 47000, loss 8.0590, acc 0.6534\n",
      "step 48000, loss 6.0443, acc 0.6540\n",
      "step 49000, loss 5.0369, acc 0.6538\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g)as sess:\n",
    "    optim=tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "    train_op=optim.minimize(loss)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(50000):\n",
    "        batch_images, batch_labels = mnist.train.next_batch(32)\n",
    "        res_loss, _ = sess.run([loss, train_op], feed_dict={\n",
    "            inputs: batch_images,\n",
    "            labels: batch_labels\n",
    "        })\n",
    "        if step % 1000 == 0:\n",
    "                accs = []\n",
    "                for test_step in range(10000 // 32):\n",
    "                    batch_images, batch_labels = mnist.test.next_batch(32)\n",
    "                    res_acc = sess.run(acc, feed_dict={\n",
    "                        inputs: batch_images,\n",
    "                        labels: batch_labels\n",
    "                    })\n",
    "                    accs.append(res_acc)\n",
    "                accs = np.mean(accs)\n",
    "                print('step %5d, loss %2.4f, acc %.4f' % (step, res_loss, accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
